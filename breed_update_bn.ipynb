{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "IMAGE_PATH = os.path.join(os.getcwd(), 'dataset/images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining transforms for images and labels. These are used for preprocessing each image used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from torchvision.models import ResNet34_Weights\n",
    "\n",
    "# get transforms from resnet\n",
    "weights = ResNet34_Weights.DEFAULT\n",
    "resnet_preprocess = weights.transforms() # this is the preprocessing done by resnet34\n",
    "\n",
    "# transforms used are those in https://pytorch.org/vision/stable/transforms.html example\n",
    "train_transform = v2.Compose([\n",
    "    # create random transform list\n",
    "    v2.RandAugment()\n",
    "])\n",
    "\n",
    "val_transform = v2.Compose([\n",
    "    v2.Resize(size=(224, 224), antialias=True),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of training/testing loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the training/test functions as implemented in \n",
    "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, device, DEBUG=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains the model provided for one epoch.\n",
    "\n",
    "    Returns:\n",
    "        results : {\n",
    "            'train_loss' : float, this is the average loss over the entire dataset,\n",
    "            'train_accuracy' : float, this is the accuracy over the entire dataset\n",
    "        }\n",
    "    \"\"\"\n",
    "    print_every = int(kwargs.get('print_every', 10))\n",
    "    data_aug = kwargs.get('data_aug', False)\n",
    "\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    with tqdm(total=num_batches, dynamic_ncols=True) as pbar:\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            #if data_aug:\n",
    "            #    X = train_transform(X)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update loss and accuracy\n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "            if DEBUG and batch % print_every == 0:\n",
    "                loss_item = loss.item()\n",
    "                pbar.set_description(f\"loss: {loss_item:>7f}  Batch:[{batch+1:>5d}/{num_batches:>5d}]\")\n",
    "            pbar.update(1)\n",
    "    \n",
    "    train_loss /= num_batches\n",
    "    train_accuracy /= len(dataloader.dataset)\n",
    "    return {\n",
    "        'train_loss' : train_loss,\n",
    "        'train_accuracy' : train_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)  # Move the data to the device\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "    return {'validation_loss': test_loss, 'validation_acc': correct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataloader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)  # Move the data to the device\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracy = 100*correct\n",
    "    return accuracy, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create a function that creates the datasets and loads the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "\n",
    "def load_data(**kwargs):\n",
    "    transform = kwargs.get('transform', None)\n",
    "    if transform is not None:\n",
    "        training_transform = v2.Compose([\n",
    "            resnet_preprocess,\n",
    "            transform\n",
    "        ])\n",
    "    else:\n",
    "        training_transform = resnet_preprocess\n",
    "    training_data = OxfordIIITPet(root='dataset', split='trainval', target_types='category', transform=training_transform, download=True)\n",
    "    validation_data = OxfordIIITPet(root='dataset', split='trainval', target_types='category', transform=resnet_preprocess, download=False)\n",
    "    test_data = OxfordIIITPet(root='dataset', split='test', target_types='category', transform=resnet_preprocess, download=False)\n",
    "\n",
    "    # shuffle and split into validation and training\n",
    "    indices = list(range(len(training_data)))\n",
    "    random.seed(310)  # fix the seed\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    train_size = int(0.8 * len(training_data))\n",
    "    train_dataset_split = Subset(training_data, indices[:train_size])\n",
    "    val_dataset_split = Subset(validation_data, indices[train_size:])\n",
    "\n",
    "    return train_dataset_split, val_dataset_split, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We define a function for creating models using different hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 37\n",
    "def create_model(**kwargs):\n",
    "    '''\n",
    "    kwargs:\n",
    "        include_layers : int, the number of layers to include in the model, 0 only includes the final layer, 1 includes the final layer and the last layer before it, etc.\n",
    "        fine_tune_bn : bool, whether to fine tune the batch normalization layers\n",
    "    '''\n",
    "    include_layers = kwargs.get('include_layers', 0)\n",
    "    fine_tune_bn = kwargs.get('fine_tune_bn', False)\n",
    "    \n",
    "    model = models.resnet34(weights='DEFAULT')\n",
    "\n",
    "    layers_to_freeze = len(list(model.children())) - include_layers \n",
    "\n",
    "    # Freeze all layers that are not included\n",
    "    for idx, layer in enumerate(model.children()):\n",
    "        # Freeze batchnorm layers if fine_tune_bn is False\n",
    "        if isinstance(layer, torch.nn.modules.batchnorm.BatchNorm2d) and not fine_tune_bn:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            if idx < layers_to_freeze:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    # Change the output layer\n",
    "    in_features = model.fc.in_features\n",
    "    #model.fc = torch.nn.Linear(in_features=in_features, out_features=num_classes, bias=True) \n",
    "    model.fc = torch.nn.Sequential(\n",
    "            nn.Linear(in_features, 512),  # Add a dense layer\n",
    "            nn.ReLU(),                 # Activation function\n",
    "            nn.Dropout(0.4),           # Dropout layer for regularization\n",
    "            nn.Linear(512, num_classes, bias=True) # Final output layer\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next we define the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_fn, optimizer, train_dataloader, val_dataloader, **kwargs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        **kwargs : {\n",
    "            'epochs' : int,\n",
    "            'device' : torch.device,\n",
    "            'scheduler' : torch.scheduler,\n",
    "            'data_aug' : bool\n",
    "        }\n",
    "    \"\"\"\n",
    "    epochs = kwargs.get('epochs', 5)\n",
    "    device = kwargs.get('device', torch.device('cpu'))\n",
    "    scheduler = kwargs.get('scheduler', None)\n",
    "\n",
    "    training_results = []\n",
    "    validation_results = []\n",
    "    best_loss = 999\n",
    "    counter = 0\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_res = train_loop(train_dataloader, model, loss_fn, optimizer, **kwargs)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        val_res = test_loop(val_dataloader, model, loss_fn, device)\n",
    "\n",
    "        # append data\n",
    "        training_results.append(train_res)\n",
    "        validation_results.append(val_res)\n",
    "\n",
    "        if val_res['validation_loss'] < best_loss:\n",
    "            best_loss = val_res['validation_loss']\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        # break if not improving for last 5 epochs\n",
    "        if t > 5 and counter == 5:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "    print(\"Training done!\")\n",
    "\n",
    "    return {'train_res': training_results, 'val_res': validation_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one graph for accuracy and one for loss\n",
    "import seaborn as sns\n",
    "# use style\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "def create_graphs(results, filename):\n",
    "    train_loss = [res['train_loss'] for res in results['train_res']]\n",
    "    val_loss = [res['validation_loss'] for res in results['val_res']]\n",
    "\n",
    "    train_acc = [res['train_accuracy'] for res in results['train_res']]\n",
    "\n",
    "    val_acc = [res['validation_acc'] for res in results['val_res']]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    sns.lineplot(x=range(1, len(train_loss)+1), y=train_loss, ax=ax[0], label='train_loss')\n",
    "    sns.lineplot(x=range(1, len(val_loss)+1), y=val_loss, ax=ax[0], label='val_loss')\n",
    "\n",
    "    sns.lineplot(x=range(1, len(train_acc)+1), y=train_acc, ax=ax[1], label='train_acc')\n",
    "    sns.lineplot(x=range(1, len(val_acc)+1), y=val_acc, ax=ax[1], label='val_acc')\n",
    "\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[1].set_title('Accuracy')\n",
    "\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "\n",
    "    plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the network using said parameters, running the test-loop on the validation set for each epoch to see if the model improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of experiments: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\\'experiment_results.csv\\', \\'w\\', newline=\\'\\') as file:\\n    writer = csv.writer(file)\\n    model_name = f\\'Layers: {len(include_layers_list)}, LR: {len(learning_rates)}, Data Aug: {len(data_augmentation_enabled)}, Fine Tune BN: {len(fine_tune_bn)}\\'\\n    writer.writerow([\"Include Layers\", \"Learning Rate\", \"Data Augmentation\", \"Fine Tune BN\", \"Test Accuracy\", \"Test Loss\"])\\n\\n    # Loop over all combinations of hyperparameters and settings\\n    for include_layers in include_layers_list:\\n        for lr in learning_rates:\\n            for data_aug in data_augmentation_enabled:\\n                for bn in fine_tune_bn:\\n                    # check if graph exists, if so, skip\\n                    graph_name = f\\'graphs/{include_layers}_{lr}_{data_aug}_{bn}.png\\'\\n                    if os.path.exists(graph_name):\\n                        print(f\"Graph already exists for {include_layers}_{lr}_{data_aug}_{bn}.png, skipping...\")\\n                        continue\\n\\n                    print(f\"Include Layers: {include_layers}, Learning Rate: {lr}, Data Augmentation: {data_aug}, Fine Tune BN: {bn}\")\\n\\n                    # Create the model and set up the layers to be fine-tuned\\n                    model = create_model(include_layers=include_layers, fine_tune_bn=bn)\\n\\n                    # Set up the optimizer\\n                    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\\n\\n                    # Set up the data augmentation transformations if enabled\\n                    if data_aug:\\n                        train_transform = v2.RandAugment()\\n                    else:\\n                        train_transform = None\\n\\n                    # Load the data\\n                    train_data, val_data, test_data = load_data(transform=train_transform)\\n\\n                    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\\n                    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\\n                    test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=False, num_workers=4)\\n                    \\n                    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\\n\\n                    # Train the model\\n                    results = train_model(model, nn.CrossEntropyLoss(), optimizer, train_dataloader, val_dataloader, epochs=_epochs, device=device, scheduler=scheduler, \\n                                data_aug=data_aug)\\n\\n                    # Evaluate the model on the validation set and get the accuracy\\n                    accuracy, test_loss = evaluate_model(test_dataloader, model, nn.CrossEntropyLoss(), device)\\n\\n                    print(f\"Test Accuracy: {accuracy:.2f}%\") \\n\\n                    # Write the results to the CSV file\\n                    writer.writerow([include_layers, lr, data_aug, bn, accuracy, test_loss])\\n\\n                    # generate graphs and save them\\n                    filename = f\\'graphs/{include_layers}_{lr}_{data_aug}_{bn}.png\\'\\n                    create_graphs(results, filename)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "# Define the hyperparameters and settings to test\n",
    "include_layers_list = [1, 2, 3] #[-999, 1, 2]\n",
    "learning_rates = [1e-3, 5e-3]\n",
    "data_augmentation_enabled = [True, False]#\", False]\n",
    "#fine_tune_bn = [True, False]\n",
    "fine_tune_bn = [True, False]\n",
    "batch_size = 64\n",
    "_epochs = 100\n",
    "\n",
    "# Number of combinations of hyperparameters and settings\n",
    "num_experiments = len(include_layers_list) * len(learning_rates) * len(data_augmentation_enabled) * len(fine_tune_bn)\n",
    "print(f\"Number of experiments: {num_experiments}\")\n",
    "\"\"\"\n",
    "with open('experiment_results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    model_name = f'Layers: {len(include_layers_list)}, LR: {len(learning_rates)}, Data Aug: {len(data_augmentation_enabled)}, Fine Tune BN: {len(fine_tune_bn)}'\n",
    "    writer.writerow([\"Include Layers\", \"Learning Rate\", \"Data Augmentation\", \"Fine Tune BN\", \"Test Accuracy\", \"Test Loss\"])\n",
    "\n",
    "    # Loop over all combinations of hyperparameters and settings\n",
    "    for include_layers in include_layers_list:\n",
    "        for lr in learning_rates:\n",
    "            for data_aug in data_augmentation_enabled:\n",
    "                for bn in fine_tune_bn:\n",
    "                    # check if graph exists, if so, skip\n",
    "                    graph_name = f'graphs/{include_layers}_{lr}_{data_aug}_{bn}.png'\n",
    "                    if os.path.exists(graph_name):\n",
    "                        print(f\"Graph already exists for {include_layers}_{lr}_{data_aug}_{bn}.png, skipping...\")\n",
    "                        continue\n",
    "\n",
    "                    print(f\"Include Layers: {include_layers}, Learning Rate: {lr}, Data Augmentation: {data_aug}, Fine Tune BN: {bn}\")\n",
    "\n",
    "                    # Create the model and set up the layers to be fine-tuned\n",
    "                    model = create_model(include_layers=include_layers, fine_tune_bn=bn)\n",
    "\n",
    "                    # Set up the optimizer\n",
    "                    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                    # Set up the data augmentation transformations if enabled\n",
    "                    if data_aug:\n",
    "                        train_transform = v2.RandAugment()\n",
    "                    else:\n",
    "                        train_transform = None\n",
    "\n",
    "                    # Load the data\n",
    "                    train_data, val_data, test_data = load_data(transform=train_transform)\n",
    "\n",
    "                    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "                    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "                    test_dataloader = DataLoader(test_data, batch_size=batch_size,shuffle=False, num_workers=4)\n",
    "                    \n",
    "                    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "                    # Train the model\n",
    "                    results = train_model(model, nn.CrossEntropyLoss(), optimizer, train_dataloader, val_dataloader, epochs=_epochs, device=device, scheduler=scheduler, \n",
    "                                data_aug=data_aug)\n",
    "\n",
    "                    # Evaluate the model on the validation set and get the accuracy\n",
    "                    accuracy, test_loss = evaluate_model(test_dataloader, model, nn.CrossEntropyLoss(), device)\n",
    "\n",
    "                    print(f\"Test Accuracy: {accuracy:.2f}%\") \n",
    "\n",
    "                    # Write the results to the CSV file\n",
    "                    writer.writerow([include_layers, lr, data_aug, bn, accuracy, test_loss])\n",
    "\n",
    "                    # generate graphs and save them\n",
    "                    filename = f'graphs/{include_layers}_{lr}_{data_aug}_{bn}.png'\n",
    "                    create_graphs(results, filename)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'imshow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# load the image\u001b[39;00m\n\u001b[1;32m     14\u001b[0m img \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimread(filename)\n\u001b[0;32m---> 15\u001b[0m ax[idx]\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     16\u001b[0m ax[idx]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m ax[idx]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData Aug: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_aug\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fine Tune BN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'imshow'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now we want to visualize the graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# show all graphs for lowest learning rate\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "for idx, data_aug in enumerate(data_augmentation_enabled):\n",
    "    for j, bn in enumerate(fine_tune_bn):\n",
    "        filename = f'graphs/1_0.001_{data_aug}_{bn}.png'\n",
    "        \n",
    "        # load the image\n",
    "        img = plt.imread(filename)\n",
    "        ax[idx].imshow(img)\n",
    "        ax[idx].axis('off')\n",
    "        ax[idx].set_title(f'Data Aug: {data_aug}, Fine Tune BN: {bn}')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
